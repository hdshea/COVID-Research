# Hourly scraping
name: jh_csse_data_scrape

# inspired by: https://github.com/orderlyquant/scrape_thb/

# Controls when the action will run.
on:
  # push:
    # branches: main
  schedule:
    - cron:  '0 4,21 * * *'
    # see: https://crontab.guru/

jobs:
  autoscrape:
    # The type of runner that the job will run on
    runs-on: macos-latest

    # Load repo and install R
    steps:
    - uses: actions/checkout@master
    - uses: r-lib/actions/setup-r@master

    # Set-up R
    - name: Install packages
      run: |
        R -e 'install.packages(c("tidyverse", "rvest", "timetk", "lubridate", "broom", "knitr", "httr"))'
    # Run R script
    - name: Scrape
      run: Rscript collect_JH_CSSE_Covid19_data.R

 # Add new files in data folder, commit along with other modified files, push
    - name: Commit files
      run: |
        git config --local user.name actions-user
        git config --local user.email "actions@github.com"
        git add Data/*
        git commit -am "GH ACTION Headlines $(date)"
        git push origin main
      env:
        REPO_KEY: ${{secrets.GITHUB_TOKEN}}
        username: github-actions
